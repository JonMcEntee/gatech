{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import gym\n",
    "import timeit\n",
    "from gym import wrappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_iterations = 10000000\n",
    "t_max = 10000\n",
    "epsilon = 1e-100\n",
    "\n",
    "env_name = 'FrozenLake8x8-v0'\n",
    "env = gym.make(env_name)\n",
    "env.seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://medium.com/@m.alzantot/deep-reinforceme\n",
    "# nt-learning-demysitifed-episode-2-policy-iteration\n",
    "# -value-iteration-and-q-978f9e89ddaa\n",
    "\n",
    "def run_episode(env, policy, gamma = 1.0, render = False):\n",
    "    \"\"\" Evaluates policy by using it to run an episode and finding its\n",
    "    total reward.\n",
    "    args:\n",
    "    env: gym environment.\n",
    "    policy: the policy to be used.\n",
    "    gamma: discount factor.\n",
    "    render: boolean to turn rendering on/off.\n",
    "    returns:\n",
    "    total reward: real value of the total reward recieved by agent under policy.\n",
    "    \"\"\"\n",
    "    obs = env.reset()\n",
    "    total_reward = 0\n",
    "    step_idx = 0\n",
    "    while True:\n",
    "        if render:\n",
    "            env.render()\n",
    "        obs, reward, done , _ = env.step(int(policy[obs]))\n",
    "        total_reward += (gamma ** step_idx * reward)\n",
    "        step_idx += 1\n",
    "        if done:\n",
    "            break\n",
    "    return total_reward\n",
    "\n",
    "\n",
    "def evaluate_policy(env, policy, gamma = 1.0,  n = 1000):\n",
    "    \"\"\" Evaluates a policy by running it n times.\n",
    "    returns:\n",
    "    average total reward\n",
    "    \"\"\"\n",
    "    scores = [\n",
    "            run_episode(env, policy, gamma = gamma, render = False)\n",
    "            for _ in range(n)]\n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value-iteration converged at iteration #2357.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.748051114998816"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def value_iteration(env, gamma = 1, v = None):\n",
    "    v = np.zeros(env.env.nS)\n",
    "    \n",
    "    for i in range(max_iterations):\n",
    "        old_v = np.copy(v)\n",
    "        for s in range(env.env.nS):\n",
    "            q_sa = [sum([gamma * p * (r + old_v[s_]) for p, s_, r, _ in env.env.P[s][a]]) for a in range(env.env.nA)]\n",
    "            v[s] = max(q_sa)\n",
    "        if np.sum(np.fabs(v - old_v)) <= epsilon:\n",
    "            print ('Value-iteration converged at iteration #%d.' %(i+1))\n",
    "            break\n",
    "    \n",
    "    return v\n",
    "\n",
    "start = timeit.default_timer()\n",
    "values = value_iteration(env, gamma = 1)\n",
    "froz_lake_vi = timeit.default_timer() - start\n",
    "\n",
    "pd.Series(values, name=\"value\").to_csv(\"value_iteration.csv\", header=True)\n",
    "froz_lake_vi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_policy(v, gamma = 1.0):\n",
    "    \"\"\" Extract the policy given a value-function \"\"\"\n",
    "    policy = np.zeros(env.env.nS)\n",
    "    for s in range(env.env.nS):\n",
    "        q_sa = np.zeros(env.env.action_space.n)\n",
    "        for a in range(env.env.action_space.n):\n",
    "            for next_sr in env.env.P[s][a]:\n",
    "                # next_sr is a tuple of (probability, next state, reward, done)\n",
    "                p, s_, r, _ = next_sr\n",
    "                q_sa[a] += (p * (r + gamma * v[s_]))\n",
    "        policy[s] = np.argmax(q_sa)\n",
    "    return policy\n",
    "\n",
    "policy = extract_policy(values)\n",
    "pd.Series(policy, name=\"policy\").to_csv(\"vi_policy.csv\", header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.854"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_policy(env, policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[41mS\u001b[0mFFFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Down)\n",
      "\u001b[41mS\u001b[0mFFFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Down)\n",
      "S\u001b[41mF\u001b[0mFFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Right)\n",
      "S\u001b[41mF\u001b[0mFFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Right)\n",
      "SFFFFFFF\n",
      "F\u001b[41mF\u001b[0mFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Up)\n",
      "SFFFFFFF\n",
      "FF\u001b[41mF\u001b[0mFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Up)\n",
      "SFFFFFFF\n",
      "FFF\u001b[41mF\u001b[0mFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Up)\n",
      "SFFFFFFF\n",
      "FF\u001b[41mF\u001b[0mFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Up)\n",
      "SF\u001b[41mF\u001b[0mFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Right)\n",
      "SF\u001b[41mF\u001b[0mFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Right)\n",
      "SF\u001b[41mF\u001b[0mFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Right)\n",
      "SFFFFFFF\n",
      "FF\u001b[41mF\u001b[0mFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Up)\n",
      "SFFFFFFF\n",
      "F\u001b[41mF\u001b[0mFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Up)\n",
      "SFFFFFFF\n",
      "FF\u001b[41mF\u001b[0mFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Up)\n",
      "SFFFFFFF\n",
      "FFF\u001b[41mF\u001b[0mFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Up)\n",
      "SFF\u001b[41mF\u001b[0mFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Down)\n",
      "SF\u001b[41mF\u001b[0mFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Right)\n",
      "SFFFFFFF\n",
      "FF\u001b[41mF\u001b[0mFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Up)\n",
      "SF\u001b[41mF\u001b[0mFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Right)\n",
      "SFF\u001b[41mF\u001b[0mFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Down)\n",
      "SFFFFFFF\n",
      "FFF\u001b[41mF\u001b[0mFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Up)\n",
      "SFF\u001b[41mF\u001b[0mFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Down)\n",
      "SFFFFFFF\n",
      "FFF\u001b[41mF\u001b[0mFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Up)\n",
      "SFF\u001b[41mF\u001b[0mFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Down)\n",
      "SFFF\u001b[41mF\u001b[0mFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Right)\n",
      "SFFFFFFF\n",
      "FFFF\u001b[41mF\u001b[0mFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Up)\n",
      "SFFFFFFF\n",
      "FFF\u001b[41mF\u001b[0mFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Up)\n",
      "SFFFFFFF\n",
      "FFFF\u001b[41mF\u001b[0mFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Up)\n",
      "SFFFFFFF\n",
      "FFF\u001b[41mF\u001b[0mFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Up)\n",
      "SFF\u001b[41mF\u001b[0mFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Down)\n",
      "SFFF\u001b[41mF\u001b[0mFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Right)\n",
      "SFFFFFFF\n",
      "FFFF\u001b[41mF\u001b[0mFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Up)\n",
      "SFFF\u001b[41mF\u001b[0mFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Right)\n",
      "SFFF\u001b[41mF\u001b[0mFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Right)\n",
      "SFFFF\u001b[41mF\u001b[0mFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Right)\n",
      "SFFFF\u001b[41mF\u001b[0mFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Right)\n",
      "SFFFF\u001b[41mF\u001b[0mFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Right)\n",
      "SFFFFF\u001b[41mF\u001b[0mF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Right)\n",
      "SFFFFFFF\n",
      "FFFFFF\u001b[41mF\u001b[0mF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Up)\n",
      "SFFFFF\u001b[41mF\u001b[0mF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Right)\n",
      "SFFFFFF\u001b[41mF\u001b[0m\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Right)\n",
      "SFFFFFF\u001b[41mF\u001b[0m\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Right)\n",
      "SFFFFFF\u001b[41mF\u001b[0m\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Right)\n",
      "SFFFFFF\u001b[41mF\u001b[0m\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Right)\n",
      "SFFFFFF\u001b[41mF\u001b[0m\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Right)\n",
      "SFFFFFF\u001b[41mF\u001b[0m\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Right)\n",
      "SFFFFFF\u001b[41mF\u001b[0m\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Right)\n",
      "SFFFFFF\u001b[41mF\u001b[0m\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Right)\n",
      "SFFFFFF\u001b[41mF\u001b[0m\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Right)\n",
      "SFFFFFF\u001b[41mF\u001b[0m\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Right)\n",
      "SFFFFFFF\n",
      "FFFFFFF\u001b[41mF\u001b[0m\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Right)\n",
      "SFFFFFF\u001b[41mF\u001b[0m\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Right)\n",
      "SFFFFFF\u001b[41mF\u001b[0m\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Right)\n",
      "SFFFFFF\u001b[41mF\u001b[0m\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Right)\n",
      "SFFFFFF\u001b[41mF\u001b[0m\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Right)\n",
      "SFFFFFFF\n",
      "FFFFFFF\u001b[41mF\u001b[0m\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Right)\n",
      "SFFFFFFF\n",
      "FFFFFFF\u001b[41mF\u001b[0m\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Right)\n",
      "SFFFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFF\u001b[41mF\u001b[0m\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Right)\n",
      "SFFFFFFF\n",
      "FFFFFFF\u001b[41mF\u001b[0m\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Right)\n",
      "SFFFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFF\u001b[41mF\u001b[0m\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Right)\n",
      "SFFFFFFF\n",
      "FFFFFFF\u001b[41mF\u001b[0m\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Right)\n",
      "SFFFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFF\u001b[41mF\u001b[0m\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Right)\n",
      "SFFFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFF\u001b[41mF\u001b[0m\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Right)\n",
      "SFFFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFF\u001b[41mF\u001b[0m\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Right)\n",
      "SFFFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHF\u001b[41mF\u001b[0m\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Right)\n",
      "SFFFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFF\u001b[41mF\u001b[0m\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Right)\n",
      "SFFFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFF\u001b[41mF\u001b[0m\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Right)\n",
      "SFFFFFFF\n",
      "FFFFFFF\u001b[41mF\u001b[0m\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Right)\n",
      "SFFFFFFF\n",
      "FFFFFFF\u001b[41mF\u001b[0m\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Right)\n",
      "SFFFFFFF\n",
      "FFFFFFF\u001b[41mF\u001b[0m\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Right)\n",
      "SFFFFFFF\n",
      "FFFFFFF\u001b[41mF\u001b[0m\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Right)\n",
      "SFFFFFFF\n",
      "FFFFFFF\u001b[41mF\u001b[0m\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Right)\n",
      "SFFFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFF\u001b[41mF\u001b[0m\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Right)\n",
      "SFFFFFFF\n",
      "FFFFFFF\u001b[41mF\u001b[0m\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Right)\n",
      "SFFFFFFF\n",
      "FFFFFFF\u001b[41mF\u001b[0m\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Right)\n",
      "SFFFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFF\u001b[41mF\u001b[0m\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Right)\n",
      "SFFFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFF\u001b[41mF\u001b[0m\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Right)\n",
      "SFFFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHF\u001b[41mF\u001b[0m\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Right)\n",
      "SFFFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHF\u001b[41mF\u001b[0m\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Right)\n",
      "SFFFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFF\u001b[41mF\u001b[0m\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Right)\n",
      "SFFFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFF\u001b[41mF\u001b[0m\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Right)\n",
      "SFFFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFH\u001b[41mF\u001b[0m\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n",
      "  (Right)\n",
      "SFFFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFH\u001b[41mF\u001b[0m\n",
      "FFFHFFFG\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_episode(env, policy, render=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Policy Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_policy_v(env, policy, gamma=1.0):\n",
    "    \"\"\" Iteratively evaluate the value-function under policy.\n",
    "    Alternatively, we could formulate a set of linear equations in iterms of v[s] \n",
    "    and solve them to find the value function.\n",
    "    \"\"\"\n",
    "    v = np.zeros(env.env.nS)\n",
    "    eps = 1e-10\n",
    "    while True:\n",
    "        prev_v = np.copy(v)\n",
    "        for s in range(env.env.nS):\n",
    "            policy_a = policy[s]\n",
    "            v[s] = sum([p * (r + gamma * prev_v[s_]) for p, s_, r, _ in env.env.P[s][policy_a]])\n",
    "        if (np.sum((np.fabs(prev_v - v))) <= eps):\n",
    "            # value converged\n",
    "            break\n",
    "    return v\n",
    "\n",
    "def policy_iteration(env, gamma = 1.0):\n",
    "    \"\"\" Policy-Iteration algorithm \"\"\"\n",
    "    policy = np.random.choice(env.env.nA, size=(env.env.nS))  # initialize a random policy\n",
    "    for i in range(max_iterations):\n",
    "        old_policy_v = compute_policy_v(env, policy, gamma)\n",
    "        new_policy = extract_policy(old_policy_v, gamma)\n",
    "        if (np.all(policy == new_policy)):\n",
    "            print ('Policy-Iteration converged at step %d.' %(i+1))\n",
    "            break\n",
    "        policy = new_policy\n",
    "    return policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy-Iteration converged at step 8.\n"
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "pi_policy = policy_iteration(env)\n",
    "froz_lake_pi = timeit.default_timer() - start\n",
    "\n",
    "pd.Series(pi_policy, name=\"policy\").to_csv(\"pi_policy.csv\", header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5997387309980695"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "froz_lake_pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q_learning(env, gamma = 1.0, alpha = 0.9):\n",
    "    # np.abs(np.random.randn())\n",
    "    first_reward = True\n",
    "    Q = np.zeros((env.observation_space.n, env.action_space.n))\n",
    "    eps = 0.99999999\n",
    "    total_reward = 0\n",
    "    for i in range(max_iterations):\n",
    "        \n",
    "        if (i + 1) % 10000 == 0:\n",
    "            print((i + 1) / 10000, \"% complete -- alpha: \", round(alpha, 2),\n",
    "                  \"-- epsilon: \", round(eps, 2), \"-- reward:\", round(total_reward, 2))\n",
    "            total_reward = 0\n",
    "            \n",
    "        obs = env.reset()\n",
    "        for t in range(t_max):\n",
    "            if np.random.uniform(0, 1) < eps:\n",
    "                action = np.random.choice(env.action_space.n)\n",
    "            else:\n",
    "                action = np.argmax(Q[obs])\n",
    "            \n",
    "            old_obs = obs\n",
    "            obs, reward, done, _ = env.step(action)\n",
    "                                    \n",
    "            predict = Q[old_obs, action]\n",
    "            target = reward + gamma * np.max(Q[obs])\n",
    "            Q[old_obs, action] = predict + alpha * (target - predict)\n",
    "            \n",
    "            total_reward += reward\n",
    "            \n",
    "            if reward != 0 and first_reward:\n",
    "                first_reward = False\n",
    "                print(\"first reward at iteration \", i, \". reward: \", reward)\n",
    "            \n",
    "            if done:\n",
    "                break\n",
    "        \n",
    "        alpha = alpha * .999999\n",
    "        eps = eps * 0.999999\n",
    "    \n",
    "    return Q\n",
    "\n",
    "def extract_q_policy(env, Q):\n",
    "    policy = np.zeros(env.observation_space.n)\n",
    "    for state in range(env.observation_space.n):\n",
    "        policy[state] = np.argmax(Q[state])\n",
    "        \n",
    "    return policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first reward at iteration  104 . reward:  1.0\n",
      "1.0 % complete -- alpha:  0.89 -- epsilon:  0.99 -- reward: 22.0\n",
      "2.0 % complete -- alpha:  0.88 -- epsilon:  0.98 -- reward: 22.0\n",
      "3.0 % complete -- alpha:  0.87 -- epsilon:  0.97 -- reward: 6.0\n",
      "4.0 % complete -- alpha:  0.86 -- epsilon:  0.96 -- reward: 19.0\n",
      "5.0 % complete -- alpha:  0.86 -- epsilon:  0.95 -- reward: 24.0\n",
      "6.0 % complete -- alpha:  0.85 -- epsilon:  0.94 -- reward: 19.0\n",
      "7.0 % complete -- alpha:  0.84 -- epsilon:  0.93 -- reward: 20.0\n",
      "8.0 % complete -- alpha:  0.83 -- epsilon:  0.92 -- reward: 23.0\n",
      "9.0 % complete -- alpha:  0.82 -- epsilon:  0.91 -- reward: 26.0\n",
      "10.0 % complete -- alpha:  0.81 -- epsilon:  0.9 -- reward: 36.0\n",
      "11.0 % complete -- alpha:  0.81 -- epsilon:  0.9 -- reward: 26.0\n",
      "12.0 % complete -- alpha:  0.8 -- epsilon:  0.89 -- reward: 27.0\n",
      "13.0 % complete -- alpha:  0.79 -- epsilon:  0.88 -- reward: 28.0\n",
      "14.0 % complete -- alpha:  0.78 -- epsilon:  0.87 -- reward: 19.0\n",
      "15.0 % complete -- alpha:  0.77 -- epsilon:  0.86 -- reward: 33.0\n",
      "16.0 % complete -- alpha:  0.77 -- epsilon:  0.85 -- reward: 24.0\n",
      "17.0 % complete -- alpha:  0.76 -- epsilon:  0.84 -- reward: 25.0\n",
      "18.0 % complete -- alpha:  0.75 -- epsilon:  0.84 -- reward: 23.0\n",
      "19.0 % complete -- alpha:  0.74 -- epsilon:  0.83 -- reward: 28.0\n",
      "20.0 % complete -- alpha:  0.74 -- epsilon:  0.82 -- reward: 27.0\n",
      "21.0 % complete -- alpha:  0.73 -- epsilon:  0.81 -- reward: 28.0\n",
      "22.0 % complete -- alpha:  0.72 -- epsilon:  0.8 -- reward: 21.0\n",
      "23.0 % complete -- alpha:  0.72 -- epsilon:  0.79 -- reward: 25.0\n",
      "24.0 % complete -- alpha:  0.71 -- epsilon:  0.79 -- reward: 27.0\n",
      "25.0 % complete -- alpha:  0.7 -- epsilon:  0.78 -- reward: 32.0\n",
      "26.0 % complete -- alpha:  0.69 -- epsilon:  0.77 -- reward: 34.0\n",
      "27.0 % complete -- alpha:  0.69 -- epsilon:  0.76 -- reward: 27.0\n",
      "28.0 % complete -- alpha:  0.68 -- epsilon:  0.76 -- reward: 30.0\n",
      "29.0 % complete -- alpha:  0.67 -- epsilon:  0.75 -- reward: 26.0\n",
      "30.0 % complete -- alpha:  0.67 -- epsilon:  0.74 -- reward: 29.0\n",
      "31.0 % complete -- alpha:  0.66 -- epsilon:  0.73 -- reward: 30.0\n",
      "32.0 % complete -- alpha:  0.65 -- epsilon:  0.73 -- reward: 40.0\n",
      "33.0 % complete -- alpha:  0.65 -- epsilon:  0.72 -- reward: 38.0\n",
      "34.0 % complete -- alpha:  0.64 -- epsilon:  0.71 -- reward: 23.0\n",
      "35.0 % complete -- alpha:  0.63 -- epsilon:  0.7 -- reward: 32.0\n",
      "36.0 % complete -- alpha:  0.63 -- epsilon:  0.7 -- reward: 35.0\n",
      "37.0 % complete -- alpha:  0.62 -- epsilon:  0.69 -- reward: 33.0\n",
      "38.0 % complete -- alpha:  0.62 -- epsilon:  0.68 -- reward: 37.0\n",
      "39.0 % complete -- alpha:  0.61 -- epsilon:  0.68 -- reward: 39.0\n",
      "40.0 % complete -- alpha:  0.6 -- epsilon:  0.67 -- reward: 39.0\n",
      "41.0 % complete -- alpha:  0.6 -- epsilon:  0.66 -- reward: 37.0\n",
      "42.0 % complete -- alpha:  0.59 -- epsilon:  0.66 -- reward: 33.0\n",
      "43.0 % complete -- alpha:  0.59 -- epsilon:  0.65 -- reward: 25.0\n",
      "44.0 % complete -- alpha:  0.58 -- epsilon:  0.64 -- reward: 39.0\n",
      "45.0 % complete -- alpha:  0.57 -- epsilon:  0.64 -- reward: 39.0\n",
      "46.0 % complete -- alpha:  0.57 -- epsilon:  0.63 -- reward: 46.0\n",
      "47.0 % complete -- alpha:  0.56 -- epsilon:  0.63 -- reward: 38.0\n",
      "48.0 % complete -- alpha:  0.56 -- epsilon:  0.62 -- reward: 44.0\n",
      "49.0 % complete -- alpha:  0.55 -- epsilon:  0.61 -- reward: 38.0\n",
      "50.0 % complete -- alpha:  0.55 -- epsilon:  0.61 -- reward: 49.0\n",
      "51.0 % complete -- alpha:  0.54 -- epsilon:  0.6 -- reward: 44.0\n",
      "52.0 % complete -- alpha:  0.54 -- epsilon:  0.59 -- reward: 39.0\n",
      "53.0 % complete -- alpha:  0.53 -- epsilon:  0.59 -- reward: 48.0\n",
      "54.0 % complete -- alpha:  0.52 -- epsilon:  0.58 -- reward: 38.0\n",
      "55.0 % complete -- alpha:  0.52 -- epsilon:  0.58 -- reward: 44.0\n",
      "56.0 % complete -- alpha:  0.51 -- epsilon:  0.57 -- reward: 47.0\n",
      "57.0 % complete -- alpha:  0.51 -- epsilon:  0.57 -- reward: 42.0\n",
      "58.0 % complete -- alpha:  0.5 -- epsilon:  0.56 -- reward: 46.0\n",
      "59.0 % complete -- alpha:  0.5 -- epsilon:  0.55 -- reward: 46.0\n",
      "60.0 % complete -- alpha:  0.49 -- epsilon:  0.55 -- reward: 32.0\n",
      "61.0 % complete -- alpha:  0.49 -- epsilon:  0.54 -- reward: 51.0\n",
      "62.0 % complete -- alpha:  0.48 -- epsilon:  0.54 -- reward: 66.0\n",
      "63.0 % complete -- alpha:  0.48 -- epsilon:  0.53 -- reward: 45.0\n",
      "64.0 % complete -- alpha:  0.47 -- epsilon:  0.53 -- reward: 39.0\n",
      "65.0 % complete -- alpha:  0.47 -- epsilon:  0.52 -- reward: 49.0\n",
      "66.0 % complete -- alpha:  0.47 -- epsilon:  0.52 -- reward: 43.0\n",
      "67.0 % complete -- alpha:  0.46 -- epsilon:  0.51 -- reward: 53.0\n",
      "68.0 % complete -- alpha:  0.46 -- epsilon:  0.51 -- reward: 60.0\n",
      "69.0 % complete -- alpha:  0.45 -- epsilon:  0.5 -- reward: 57.0\n",
      "70.0 % complete -- alpha:  0.45 -- epsilon:  0.5 -- reward: 58.0\n",
      "71.0 % complete -- alpha:  0.44 -- epsilon:  0.49 -- reward: 50.0\n",
      "72.0 % complete -- alpha:  0.44 -- epsilon:  0.49 -- reward: 50.0\n",
      "73.0 % complete -- alpha:  0.43 -- epsilon:  0.48 -- reward: 62.0\n",
      "74.0 % complete -- alpha:  0.43 -- epsilon:  0.48 -- reward: 52.0\n",
      "75.0 % complete -- alpha:  0.43 -- epsilon:  0.47 -- reward: 49.0\n",
      "76.0 % complete -- alpha:  0.42 -- epsilon:  0.47 -- reward: 55.0\n",
      "77.0 % complete -- alpha:  0.42 -- epsilon:  0.46 -- reward: 49.0\n",
      "78.0 % complete -- alpha:  0.41 -- epsilon:  0.46 -- reward: 58.0\n",
      "79.0 % complete -- alpha:  0.41 -- epsilon:  0.45 -- reward: 57.0\n",
      "80.0 % complete -- alpha:  0.4 -- epsilon:  0.45 -- reward: 56.0\n",
      "81.0 % complete -- alpha:  0.4 -- epsilon:  0.44 -- reward: 56.0\n",
      "82.0 % complete -- alpha:  0.4 -- epsilon:  0.44 -- reward: 52.0\n",
      "83.0 % complete -- alpha:  0.39 -- epsilon:  0.44 -- reward: 41.0\n",
      "84.0 % complete -- alpha:  0.39 -- epsilon:  0.43 -- reward: 68.0\n",
      "85.0 % complete -- alpha:  0.38 -- epsilon:  0.43 -- reward: 45.0\n",
      "86.0 % complete -- alpha:  0.38 -- epsilon:  0.42 -- reward: 55.0\n",
      "87.0 % complete -- alpha:  0.38 -- epsilon:  0.42 -- reward: 56.0\n",
      "88.0 % complete -- alpha:  0.37 -- epsilon:  0.41 -- reward: 66.0\n",
      "89.0 % complete -- alpha:  0.37 -- epsilon:  0.41 -- reward: 49.0\n",
      "90.0 % complete -- alpha:  0.37 -- epsilon:  0.41 -- reward: 59.0\n",
      "91.0 % complete -- alpha:  0.36 -- epsilon:  0.4 -- reward: 56.0\n",
      "92.0 % complete -- alpha:  0.36 -- epsilon:  0.4 -- reward: 75.0\n",
      "93.0 % complete -- alpha:  0.36 -- epsilon:  0.39 -- reward: 75.0\n",
      "94.0 % complete -- alpha:  0.35 -- epsilon:  0.39 -- reward: 54.0\n",
      "95.0 % complete -- alpha:  0.35 -- epsilon:  0.39 -- reward: 43.0\n",
      "96.0 % complete -- alpha:  0.34 -- epsilon:  0.38 -- reward: 65.0\n",
      "97.0 % complete -- alpha:  0.34 -- epsilon:  0.38 -- reward: 60.0\n",
      "98.0 % complete -- alpha:  0.34 -- epsilon:  0.38 -- reward: 61.0\n",
      "99.0 % complete -- alpha:  0.33 -- epsilon:  0.37 -- reward: 60.0\n",
      "100.0 % complete -- alpha:  0.33 -- epsilon:  0.37 -- reward: 70.0\n",
      "101.0 % complete -- alpha:  0.33 -- epsilon:  0.36 -- reward: 69.0\n",
      "102.0 % complete -- alpha:  0.32 -- epsilon:  0.36 -- reward: 65.0\n",
      "103.0 % complete -- alpha:  0.32 -- epsilon:  0.36 -- reward: 78.0\n",
      "104.0 % complete -- alpha:  0.32 -- epsilon:  0.35 -- reward: 69.0\n",
      "105.0 % complete -- alpha:  0.31 -- epsilon:  0.35 -- reward: 68.0\n",
      "106.0 % complete -- alpha:  0.31 -- epsilon:  0.35 -- reward: 58.0\n",
      "107.0 % complete -- alpha:  0.31 -- epsilon:  0.34 -- reward: 65.0\n",
      "108.0 % complete -- alpha:  0.31 -- epsilon:  0.34 -- reward: 65.0\n",
      "109.0 % complete -- alpha:  0.3 -- epsilon:  0.34 -- reward: 78.0\n",
      "110.0 % complete -- alpha:  0.3 -- epsilon:  0.33 -- reward: 71.0\n",
      "111.0 % complete -- alpha:  0.3 -- epsilon:  0.33 -- reward: 43.0\n",
      "112.0 % complete -- alpha:  0.29 -- epsilon:  0.33 -- reward: 64.0\n",
      "113.0 % complete -- alpha:  0.29 -- epsilon:  0.32 -- reward: 64.0\n",
      "114.0 % complete -- alpha:  0.29 -- epsilon:  0.32 -- reward: 60.0\n",
      "115.0 % complete -- alpha:  0.28 -- epsilon:  0.32 -- reward: 67.0\n",
      "116.0 % complete -- alpha:  0.28 -- epsilon:  0.31 -- reward: 75.0\n",
      "117.0 % complete -- alpha:  0.28 -- epsilon:  0.31 -- reward: 65.0\n",
      "118.0 % complete -- alpha:  0.28 -- epsilon:  0.31 -- reward: 61.0\n",
      "119.0 % complete -- alpha:  0.27 -- epsilon:  0.3 -- reward: 61.0\n",
      "120.0 % complete -- alpha:  0.27 -- epsilon:  0.3 -- reward: 78.0\n",
      "121.0 % complete -- alpha:  0.27 -- epsilon:  0.3 -- reward: 87.0\n",
      "122.0 % complete -- alpha:  0.27 -- epsilon:  0.3 -- reward: 68.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-291-23eda7665bcd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mQ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mq_learning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-290-a13e4ceed15d>\u001b[0m in \u001b[0;36mq_learning\u001b[0;34m(env, gamma, alpha)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m                 \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Q = q_learning(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_policy = extract_q_policy(env, Q)\n",
    "pd.Series(new_policy, name=\"policy\").to_csv(\"q_policy.csv\", header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_policy(env, new_policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
