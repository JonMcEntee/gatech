---
title: "Machine Learning - Assignment 2"
author: "Jonathan McEntee"
date: "10/3/2018"
output:
  pdf_document
#classoption: twocolumn
header-includes:
  \usepackage{tikz}
  \usetikzlibrary{matrix,chains,positioning,decorations.pathreplacing,arrows}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(tidyverse)
library(extrafont)
library(grid)
library(gridExtra)

adult_results <- read_csv("results/adult_results.csv")
adult_finals <- read_csv("results/adult_finals.csv")

count_ones_results <- read_csv("results/count_ones_results.csv")
count_ones_finals <- read_csv("results/count_ones_finals.csv")
count_ones_iterations <- read_csv("new_results/count_ones_finals.csv")

continuous_peaks_results <- read_csv("results/continuous_peaks_results.csv")
continuous_peaks_finals <- read_csv("results/continuous_peaks_finals.csv")
continuous_peaks_iterations <- read_csv("new_results/continuous_peaks_finals.csv")

flip_flop_results <- read_csv("results/flip_flop_results.csv")
flip_flop_finals <- read_csv("results/flip_flop_finals.csv")
flip_flop_iterations <- read_csv("new_results/flip_flop_finals.csv")

four_peaks_results <- read_csv("results/four_peaks_results.csv")
four_peaks_finals <- read_csv("results/four_peaks_finals.csv")
four_peaks_iterations <- read_csv("new_results/four_peaks_finals.csv")

plot_data <- function(df, title=NULL, subtitle=NULL,
                      xlab=NULL, ylab=NULL, invert=FALSE,
                      justification = c(1,0)) {
  
  if (invert) df <- df %>% mutate(score = 1/score)
  
  df %>%
    group_by(algorithm) %>%
    mutate(x = iteration / n()) %>%
    ungroup() %>%
    ggplot(aes(x = x, y = score, color = algorithm)) +
    geom_line() +
    # geom_point() +
    theme_minimal() +
    theme(
      plot.title = element_text(face = "bold"),
      legend.position = justification,
      legend.justification = justification,
      text = element_text(size = 10, family = "CMU Serif")
    ) +
    labs(
      title = title,
      subtitle = subtitle,
      x = xlab,
      y = ylab,
      color = NULL
    )
}

plot_time_iterations <- function(df, title) {
  new_data <- df %>%
    group_by(algorithm, bitstring_size) %>%
    summarize(
      score = mean(score),
      iterations = mean(iterations),
      training_time = mean(training_time)
    ) %>%
    ungroup()

  p1 <- new_data %>%
    ggplot(aes(x = bitstring_size, y = training_time, color = algorithm)) +
    geom_line() +
    geom_point() +
    theme_minimal() +
    theme(
      legend.position = c(0,1),
      legend.justification = c(0,1),
      panel.grid.major.x = element_blank(),
      panel.grid.minor.x = element_blank(),
      text = element_text(size = 10, family = "CMU Serif")
    ) +
    labs(
      color = NULL,
      x = NULL,
      y = "Training Time (Seconds)"
    )
  
  p2 <- new_data %>%
    ggplot(aes(x = bitstring_size, y = iterations, fill = algorithm)) +
    theme_minimal() +
    geom_bar(stat = "identity", position = "dodge", width = 4) +
    guides(fill = FALSE) +
    labs(x = NULL) +
    scale_y_continuous(position = "right") +
    theme(
      panel.grid.major.x = element_blank(),
      panel.grid.minor.x = element_blank(),
      text = element_text(size = 10, family = "CMU Serif")
    ) +
    labs(
      y = "Iterations"
    )
    
  
  grid.arrange( grobs = list(p1, p2), nrow = 1,
                top = textGrob(title, x = .07, hjust = 0,
                               gp = gpar(fontfamily = "CMU Serif", fontsize = 12, fontface = "bold")),
                bottom = textGrob("Bitstring Size", gp = gpar(fontfamily = "CMU Serif", fontsize = 10)))
}
```

# Neural Network Weights With Randomized Optimization

The first experiment carried out, using the ABAGAIL library for java, applied three randomized optimization algorithms (randomized hill climbing, simulated annealing, and a genetic algorithm) to the problem of finding optimal weights for a neural network. Gradient descent was also performed for comparison. The neural network had fourteen inputs, an output node, and used a single hidden layer with five nodes. The objective of each algorithm was to minimize the sum of squares error between the categorical target value (0 or 1) and the output of the neural net. Put more precisely, the loss function for this experiment was:

$$error = \sum_{n=1}^m (t_i - o_i)^2$$
Where $t_i$ is the target value of the ith instance and $o_i$ was the output of the neural net for the ith instance.

## Adult Data Set

The Adult dataset has 32,000+ samples and features for each adult including their age, sex, race, etc. In my last experiment I subsampled the full dataset down to 6000 samples to save time on training. This time all 32,000+ samples were used. I also pre-processed the data: first selecting the 14 most relevant attributes, then scaling the data so all sample features were between -1 and 1, to prevent overdependence on variables with a larger range. The objective, as before, is to estimate whether the adult represented by the sample has an income greater than $50,000.

## Results

The four algorithms were trained for 1000 iterations each on the adult data.\newline

```{r, fig.width=6, fig.height=3, message=FALSE, warning=FALSE, fig.align="center"}
adult_results %>%
  plot_data(
    title = "Squared Error vs. Iterations on Adult Dataset",
    subtitle = "For Various Randomized Optimization Algorithms",
    xlab = "Iterations",
    ylab = "Error",
    invert = TRUE,
    justification = c(1,1))
```

The leftmost point for each algorithm on the graph above represents the sum of squares error (over the training data) after one iteration. By the time one iteration has passed, the gradient descent backpropagation algorithm has already reduced its squared error to 3933, lower than any of the randomized algorithms. It then quickly converges to about 1630, and (very, very slowly) continues to drop. The speed and accuracy with which gradient descent fits data is why it is often the first choice for training neural nets.

Randomized hill climbing ekes out second place. Though randomized hill climbing is completely unable to remove itself from local optima, that didn't seem to hurt it much in this case. The simulated annealing algorithm stands out the most when graphed. It rises and falls, although the rises are less high as the algorithm iterates. This is what we expect as the simulated annealing algorithm's temperature paramater cools over time, making the algorithm less likely to accept a value which raises the error. It is unable to converge in the same was as the other algorithms within 1000 iterations and has the highest error.

The genetic algorithm has a similar trajectory to the randomized algorithm in that it quickly declines and levels out, but it also apparently rises in some places. This is because the genetic algorithm doesn't necessarily hold on to its fittest member between generations. The algorithm generates a distribution which weights each member of its population by fitness, and then samples from that distribution. This is to prevent falling into local optima. However the genetic algorithm ultimately had a higher error than randomized hill climbing and a much longer training time.

```{r}
adult_finals %>%
  mutate(
    accuracy = paste0(accuracy %>% round(1), "%"),
    training_time = paste(round(training_time / 60, 1), "min"),
    test_time = paste(round(test_time, 1), "sec"),
    algorithm = recode(algorithm,
                       RHC = "Randomized Hill Climbing",
                       GA = "Genetic Algorithm",
                       SA = "Simulated Annealing",
                       GD = "Gradient Descent")
  ) %>%
  rename(
    Algorithm = algorithm,
    Correct = classified_correctly,
    Incorrect = classified_incorrectly,
    Accuracy = accuracy,
    `Training Time` = training_time,
    `Test Time` = test_time
  ) %>%
  knitr::kable()
```

# The "Count Ones" Problem

The "count ones" problem, as the name suggests, is an optimization problem on bitstrings where the evaluation function simply counts the number of ones in the bitstring. The more ones, the higher its fitness score. For example, if the bit strings were 5 bits long, then a string 10111 would be given a score of 4. The order of the bits plays no importance, so 11101 would recieve the same score.

Because the evaluation function doesn't account for the order of the bits, there are no conditional dependencies between them. So we would expect MIMIC and genetic algorithms to have no particular advantage against truly structureless optimization algorithms like randomized hill climbing and simulated annealing.

There is also only one optimum in this problem, so the randomized hill climbing algorithm will not get "stuck" at local optima. What do I mean by this? Consider the randomized hill climbing algorithm's neighbor function in ABAGAIL. The neighbor of the randomized hill climbing algorithm's current bitsrting is that same bitstring but with one randomly selected bit changed. So the string 10010 has the neighbors 00010, 11010, 10110, 10000, and 10011. This means that for any suboptimal bit string, there will always be a neighbor that improves the fitness score.

With no local optimums to be trapped in, simulated annealing shouldn't have any advantage over randomized hill climbing either.

```{r, fig.width=6, fig.height=3, message=FALSE, fig.align="center"}
count_ones_results %>%
  filter(run_num == 3) %>%
  mutate(score = as.double(score)) %>%
  plot_data(
    title = 'The "Count Ones" Problem',
    xlab = "Iterations",
    ylab = "Score")
```

I ran all four algorithms against solving the count ones problem with 100-bit long bitstrings 100 times. On average, randomized hill climbing performed the best. Simulated annealing was second best, followed by MIMIC. The genetic algorithm performed the worst. In fact, it performed much worse. While the other three algorithms averaged in the high 90s (the highest score being 100), the genetic algorithm averaged 59 points. Why?

It's unlikely to be the mutation function, which is identical to the neighbor function for randomized hill climbing and simulated annealing in this test. One possibility is that the discrete uniform crossover function applied to the genetic algorithm is ill-suited for the count ones problem. The function takes the two parent bitstrings, and for each bit of the child bitstring chooses the existing bit from one of its parents, with a 50-50 chance of choosing one or the other.

Suppose our genetic algorithm reaches a point where on average, its population has 50 points. That means the "average"" bitstring in the population has 25 ones and 25 zeros. Which furthermore means the "average"" mutation operation is combining two bitstrings that are 50 percent zero and 50 percent ones. So each bit in the child bitstring will on average have a 50 percent chance of being a one or a zero.

With this in mind, we can see that the bitstrings being generated by the mutation function are something like a binomial distribution where $p = 0.5$. And the most likely outcome is that it will produce another bitstring with 50% ones and 50% zeros, or something close. With the selection phase throwing out those bitstrings with lower scores, the GA *should* be able to eventually pull its score up. However it's easy to see how the genetic algorithm could get "stuck" on the count ones problem.

```{r, fig.width=6, fig.height=3, message=FALSE, fig.align="center"}
plot_time_iterations(count_ones_iterations,
                     title = 'Iteration/Time on "Count Ones" To Reach Perfect Score')
```

```{r}
count_ones_finals %>%
  group_by(algorithm) %>%
  summarize(
    score = mean(score),
    iterations = mean(iterations),
    training_time = mean(training_time)
  ) %>%
  ungroup() %>%
  mutate(
    training_time = paste(round(training_time, 1), "sec"),
    algorithm = recode(algorithm,
                       RHC = "Randomized Hill Climbing",
                       GA = "Genetic Algorithm",
                       SA = "Simulated Annealing")
  ) %>%
  rename(
    Algorithm = algorithm,
    Score = score,
    `Training Time` = training_time
  ) %>%
  arrange(desc(Score)) %>%
  knitr::kable()
```

# Solving The "Flip Flop" Problem With Randomized Optimization

```{r, fig.width=6, fig.height=3, message=FALSE, fig.align="center"}
flip_flop_results %>%
  filter(run_num == 4) %>%
  plot_data(
    title = "The 'Flip Flop' Problem",
    xlab = "Iterations",
    ylab = "Score")
```

```{r, fig.width=6, fig.height=3, message=FALSE, fig.align="center"}
plot_time_iterations(flip_flop_iterations %>% filter(algorithm != "RHC"),
                     title = 'Iteration/Time on "Flip Flop" To Reach Perfect Score')
```


```{r, fig.width=6, fig.height=3, message=FALSE, fig.align="center"}
continuous_peaks_results %>%
  filter(run_num == 4) %>%
  plot_data(
    title = "The 'Continuous Peaks' Problem",
    xlab = "Iterations",
    ylab = "Error")
```

```{r, fig.width=6, fig.height=3, message=FALSE, fig.align="center"}
plot_time_iterations(continuous_peaks_iterations,
                     title = 'Iteration/Time on "Continuous Peaks" To Reach Perfect Score')
```

```{r}
continuous_peaks_finals %>%
  group_by(algorithm) %>%
  summarize(
    score = mean(score),
    iterations = mean(iterations),
    training_time = mean(training_time)
  ) %>%
  ungroup() %>%
  mutate(
    training_time = paste(round(training_time, 1), "sec"),
    algorithm = recode(algorithm,
                       RHC = "Randomized Hill Climbing",
                       GA = "Genetic Algorithm",
                       SA = "Simulated Annealing")
  ) %>%
  rename(
    Algorithm = algorithm,
    Score = score,
    `Training Time` = training_time
  ) %>%
  arrange(desc(Score)) %>%
  knitr::kable()
```


```{r, fig.width=6, fig.height=3, message=FALSE, fig.align="center"}
four_peaks_results %>%
  filter(run_num == 14) %>%
  plot_data(
    title = "The 'Four Peaks' Problem",
    xlab = "Iterations",
    ylab = "Error")
```

```{r, fig.width=6, fig.height=3, message=FALSE, fig.align="center"}
plot_time_iterations(four_peaks_iterations,
                     title = 'Iteration/Time on "Four Peaks" To Reach Perfect Score')
```

```{r}
four_peaks_finals %>%
  group_by(algorithm) %>%
  summarize(
    score = mean(score),
    iterations = mean(iterations),
    training_time = mean(training_time)
  ) %>%
  ungroup() %>%
  mutate(
    training_time = paste(round(training_time, 1), "sec"),
    algorithm = recode(algorithm,
                       RHC = "Randomized Hill Climbing",
                       GA = "Genetic Algorithm",
                       SA = "Simulated Annealing")
  ) %>%
  rename(
    Algorithm = algorithm,
    Score = score,
    `Training Time` = training_time
  ) %>%
  arrange(desc(Score)) %>%
  knitr::kable()
```
